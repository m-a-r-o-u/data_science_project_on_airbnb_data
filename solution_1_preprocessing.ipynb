{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Exploration and Preparation\n",
    "\n",
    "---\n",
    "\n",
    "**Content**\n",
    "\n",
    "- Data Exploration\n",
    "\n",
    "- Data Preprocessing\n",
    "\n",
    "- Feature Engineering\n",
    "\n",
    "- Save Features to Disk\n",
    "\n",
    "\n",
    "\n",
    "**Additional Material**\n",
    "\n",
    "- pandas dashboard library [pandas-profiling](https://github.com/ydataai/pandas-profiling)\n",
    "\n",
    "- geospatial data processing library  [cartopy](https://scitools.org.uk/cartopy/docs/latest/installing.html)\n",
    "\n",
    "\n",
    "**Central Concepts**\n",
    "\n",
    "- Data Leakage\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "- Solve the tasks indicated by the keyword **TODO**\n",
    "\n",
    "- Solve the tasks **sequentially**, variable names are recycled, can lead to inconsistencies.\n",
    "\n",
    "- Read the description carefully (typo's are human, use common sense)\n",
    "\n",
    "- Follow the structure given in the **TIP**\n",
    "\n",
    "- **INSERT SOLUTION** indicates how many columns our solution had.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib color settings\n",
    "\n",
    "dark_plot_theme = True\n",
    "\n",
    "if dark_plot_theme:\n",
    "    plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load general dependencies\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# for geographic data\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from geopy.distance import great_circle \n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and refresh custom functions\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import get_dichotomous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas display settings\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the working directory\n",
    "\n",
    "cwd = Path()\n",
    "\n",
    "opath = cwd / 'data'\n",
    "ppath = cwd / 'plots'\n",
    "\n",
    "opath.mkdir(exist_ok=True)\n",
    "ppath.mkdir(exist_ok=True)\n",
    "\n",
    "ifname = opath / 'listings.csv'\n",
    "ofname = opath / 'features.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #extract specific columns of the raw data\n",
    "\n",
    "index = ['id']\n",
    "\n",
    "cnames = []\n",
    "cnames += [\"space\"]\n",
    "cnames += [\"description\"]\n",
    "cnames += [\"host_since\"]\n",
    "cnames += [\"host_is_superhost\"]\n",
    "cnames += [\"neighbourhood_group_cleansed\"]\n",
    "cnames += [\"latitude\"]\n",
    "cnames += [\"longitude\"]\n",
    "cnames += [\"room_type\"]\n",
    "cnames += [\"bathrooms\"]\n",
    "cnames += [\"bedrooms\"]\n",
    "cnames += [\"beds\"]\n",
    "cnames += [\"amenities\"]\n",
    "cnames += [\"square_feet\"]\n",
    "cnames += [\"price\"]\n",
    "cnames += [\"cleaning_fee\"]\n",
    "cnames += [\"security_deposit\"]\n",
    "cnames += [\"minimum_nights\"]\n",
    "cnames += [\"number_of_reviews\"]\n",
    "cnames += [\"review_scores_rating\"]\n",
    "cnames += [\"review_scores_cleanliness\"]\n",
    "cnames += [\"review_scores_location\"]\n",
    "cnames += [\"instant_bookable\"]\n",
    "cnames += [\"host_id\"]\n",
    "cnames += index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# load in the csv file: \"ifname\"\n",
    "# use pandas pd.read_csv\n",
    "# and specify columns: \"cnames\"\n",
    "# and the index column: \"index\"\n",
    "\n",
    "# TIP:\n",
    "# data = \n",
    "\n",
    "data = pd.read_csv(ifname, usecols=cnames, index_col=index).sort_index(axis=1) # REMOVE\n",
    "\n",
    "# process and gather features in odata\n",
    "odata = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if len(data.columns) == 23:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of columns, try again')\n",
    "\n",
    "if data.index.name == 'id':\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong index, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "---\n",
    "\n",
    "The first data exploration is done with\\\n",
    "the help of the pandas-profiling package.\n",
    "\n",
    "The report is generated by running the notebook:\n",
    "\n",
    "`create_repots.ipynb`\n",
    "\n",
    "This will generated the report of the raw data:\n",
    "\n",
    "./plots/data_report_raw.html\n",
    "\n",
    "It is an html file so view it in the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform monetary string to numeric variables\n",
    "\n",
    "variables = ['price', 'cleaning_fee', 'security_deposit']\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for v in variables:\n",
    "    # TODO:\n",
    "    # The \"variables\" are strings convert them into floats.\n",
    "    # Therefore, remove the characters: \"$\" and \",\".\n",
    "    # Use pandas \"str.replace\" and \"astype\".\n",
    "\n",
    "    # TIP:\n",
    "    # result[v] = data[v]...\n",
    "    \n",
    "    result[v] = data[v].str.replace('[$,]', '', regex=True).astype(float) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if result['price'].dtype == 'float':\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables are not float, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if np.floor(result['price'].sum()) in [1514224, 1322728]:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata[variables] = result[variables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform boolean strings to numbers\n",
    "\n",
    "variables = ['host_is_superhost', 'instant_bookable']\n",
    "\n",
    "d = {'t': 1., 'f': 0.}\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for v in variables:\n",
    "    # TODO:\n",
    "    # Convert the \"variables\" from string to float.\n",
    "    # Therefore, use the provided dictionary \"d\"\n",
    "    # and the pandas \".map\" function.\n",
    "    # Furthermore, specify how to handle Null values in \"map\".\n",
    "\n",
    "    # TIP:\n",
    "    # result[v] = data[v]...\n",
    "    \n",
    "    result[v] = data[v].map(d, na_action='ignore') # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if result['host_is_superhost'].sum() == 3011:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "\n",
    "if result['host_is_superhost'].isnull().sum() == 26:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata[variables] = result[variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specific amenities from the \n",
    "\n",
    "amenities = data['amenities'].str.strip('{}').str.replace('\"', '').str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Count the appearances of the individual amenities in the variables \"amenities\"\n",
    "# First flatten the nested \"amenities\" variable with panda \"explode\" function.\n",
    "# Then use the \"Counter\" class from the \"collections\" library.\n",
    "# Counter: dict like, stores names as keys and counts as values\n",
    "\n",
    "# TIP:\n",
    "# counter = ...\n",
    "\n",
    "counter = Counter(amenities.explode()) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if counter['TV'] == 10134:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the TV in counter does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot found amenities\n",
    "\n",
    "# the 70 most frequent amenities\n",
    "df_counter = pd.DataFrame(list(counter.items()), columns=['amenities', 'count']).sort_values('count', ascending=False).head(70)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 12))\n",
    "\n",
    "# TODO:\n",
    "# Visualize the amenities in the df_counter DataFrame.\n",
    "# Use the \"barplot\" function from the \"seaborn\" (imported as sns) library\n",
    "# Set the x to \"count\" and y to \"amenities\".\n",
    "# What is the most frequent amenity?\n",
    "\n",
    "# TIP:\n",
    "# sns.barplot(...)\n",
    "\n",
    "sns.barplot(data=df_counter, y='amenities', x='count'); # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dummy variables for the amenities\n",
    "\n",
    "features = []\n",
    "\n",
    "nv = 'family'\n",
    "pattern = 'Crib|Family/kid friendly|Baby|Children'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'smoking'\n",
    "pattern = 'Smoking allowed'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'TV'\n",
    "pattern = 'TV'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'internet'\n",
    "pattern = 'WiFi|Internet'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'pets'\n",
    "pattern = 'Pets allowed'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'parking'\n",
    "pattern = 'Parking|parking'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "v = 'amenities'\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for nv, pattern in features:\n",
    "    # TODO:\n",
    "    # We create new dummy variables if special amenities are present.\n",
    "    # The new variable names \"nv\" are looped over together with the \"pattern\".\n",
    "    # If the pattern is present return true and cast to 1.\n",
    "    # For this use pandas \".str.contains\"\n",
    "    # and set the type with \"astype\" to integer.\n",
    "\n",
    "    # TIP:\n",
    "    # result[nv] = data[v].str...\n",
    "    \n",
    "    result[nv] = data[v].str.contains(pattern).astype('uint8') # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if result['internet'].sum() == 7909:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the internet variable does not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata = pd.concat([odata, result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up kitchen amenities\n",
    "\n",
    "nv = 'basic_kitchen'\n",
    "dtype = 'uint8'\n",
    "odata[nv] = np.sum([odata[v].str.contains('Coffee').astype(dtype),\n",
    "                  odata[v].str.contains('Dishes').astype(dtype),\n",
    "                  odata[v].str.contains('Oven').astype(dtype),\n",
    "                  odata[v].str.contains('Dishwasher').astype(dtype),\n",
    "                  odata[v].str.contains('Microwave').astype(dtype),\n",
    "                  odata[v].str.contains('Refrigerator').astype(dtype),\n",
    "                  odata[v].str.contains('Dishwasher').astype(dtype),\n",
    "                  odata[v].str.contains('Cooking basics').astype(dtype)],\n",
    "                 axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract square meters from the description\n",
    "\n",
    "v = 'square_feet'\n",
    "nv = 'square_meter'\n",
    "\n",
    "pattern = '(\\d{2,4})\\s?(sq\\s*m|square\\s*m|quadrate\\s*meter|m2|m\\^2|m²|mq)'\n",
    "m_per_ft = 0.3048\n",
    "\n",
    "sqm_from_desc = data['description'].str.extract(pattern, flags=re.IGNORECASE)[0].astype('float64')\n",
    "\n",
    "# TODO:\n",
    "# Combine the data from the dataframe column \"square_feet\"\n",
    "# with the values extracted into \"sqm_from_desc\"\n",
    "# First change units from SQUARE feet to SQUARE meter using m_per_ft**2\n",
    "# Then use the pandas function \"combine_first\"\n",
    "# To combine the output in to the new variable \"square_meter\" (nv)\n",
    "\n",
    "# TIP:\n",
    "# odata[nv] = (data[v] * ... ).combine_first( ... )\n",
    "\n",
    "odata[nv] = (data[v] * m_per_ft**2).combine_first(sqm_from_desc) # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if np.floor(odata['square_meter'].sum()) == 285489:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the square_meter variable does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Replace all zeros with np.nan\n",
    "# in the \"square_meter\" variable.\n",
    "# Use the pandas \"replace\" function\n",
    "\n",
    "# TIP:\n",
    "# result = odata[nv]...\n",
    "\n",
    "result = odata[nv].replace(0, np.nan) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if (result < 0.1).sum() == 0:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the numbers do not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata[nv] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of listings per host\n",
    "# using a pandas cookbook trick\n",
    "\n",
    "# TODO:\n",
    "# Create the new variable 'listings/host' in :\n",
    "# which contains the count of listings per host\n",
    "# This trick works by grouping the data after the \"host_id\"\n",
    "# and then using \"transform\" to count the elements in each group\n",
    "# with the \"len\" function\n",
    "# But you need a second dummy variable: \"beds\"\n",
    "\n",
    "# TIP:\n",
    "# result = odata[['host_id', ...]].groupby(...).transform(...);\n",
    "\n",
    "result = odata[['host_id', 'beds']].groupby(\"host_id\").transform(len); # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed =[]\n",
    "\n",
    "if result.loc[2015].values[0] == 4:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the variable does not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata['listings/host'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of years_registered\n",
    "\n",
    "class YSR:\n",
    "    def __init__(self, dates):\n",
    "        self.reference = dates.max()\n",
    "\n",
    "    def __call__(self, date):\n",
    "        return np.abs((self.reference - date).days / 356)\n",
    "\n",
    "# TODO:\n",
    "# To calculate the \"years_registered\" feature\n",
    "# The feature \"host_since\" needs to be converted to_datetime.\n",
    "# Use the pandas utility function to_datetime\n",
    "\n",
    "# TIP:\n",
    "# host_since = pd...\n",
    "\n",
    "host_since = pd.to_datetime(odata['host_since']) # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if isinstance(host_since.iloc[0], datetime.datetime):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the variable does not add up, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata['years_registered'] = host_since.apply(YSR(host_since))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning of years_registered\n",
    "\n",
    "bins = [0, 1, 4, np.inf]\n",
    "\n",
    "groups = ['Newbies','Experienced','Professionals']\n",
    "\n",
    "# TODO:\n",
    "# Use pandas cut function to bin \"years_registered\"\n",
    "# into \"bins\" with the labels given by \"groups\".\n",
    "# Save the result in the feature \"host_since_cat\".\n",
    "\n",
    "# TIP:\n",
    "# result = pd.cut(...)\n",
    "\n",
    "result = pd.cut(odata['years_registered'], bins, labels=groups) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if 'Professionals' in result.unique():\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** no Professionals found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata['host_since_cat'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show years_registered\n",
    "\n",
    "# TODO:\n",
    "# Take a quick look at the results.\n",
    "# Use the seaborn \"countplot\" routine.\n",
    "\n",
    "# TIP:\n",
    "# sns.countplot(...)\n",
    "\n",
    "sns.countplot(x=odata['host_since_cat']); # REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encode\n",
    "\n",
    "vs = ['room_type', 'neighbourhood_group_cleansed', 'host_since_cat']\n",
    "\n",
    "# TODO:\n",
    "# Create dummy variable from the variables in \"vs\"\n",
    "# Use the dedicated pandas convenience function\n",
    "# for this task: \"get_dummies\"\n",
    "\n",
    "# TIP:\n",
    "# dummies =\n",
    "\n",
    "dummies = pd.get_dummies(odata[vs]) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if len(dummies.columns) == 18:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of dummy variables found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata = odata.join(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download/extract berlin shape files\n",
    "\n",
    "url = \"https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.shp.zip\"\n",
    "\n",
    "shp_folder = opath / 'berlin_shape_files'\n",
    "shp_folder.mkdir(exist_ok=True)\n",
    "shp_fname_zip = shp_folder / os.path.basename(url)\n",
    "\n",
    "response = requests.get(url)\n",
    "open(shp_fname_zip, \"wb\").write(response.content);\n",
    "\n",
    "with zipfile.ZipFile(shp_fname_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(shp_folder)\n",
    "\n",
    "shp_fname = list(opath.rglob('*.shp'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spatial price distribution\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "figsize = (12, 8)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "\n",
    "berlin = gpd.read_file(shp_fname)\n",
    "berlin.plot(edgecolor='black', ax=ax);\n",
    "\n",
    "scatter_plot = ax.scatter(odata['longitude'], odata['latitude'], c=odata['price'], cmap='inferno_r', vmax=600, s=0.7)\n",
    "cbar = plt.colorbar(scatter_plot, ax=ax)\n",
    "cbar.ax.set_ylabel('price')\n",
    "\n",
    "ax.set_title('Berlin', fontsize='xx-large')\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=0)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add variables that contain the distance to important places like the central station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances to special places\n",
    "\n",
    "\n",
    "# dict of special places: coordinates (lat, lon)\n",
    "locations = {}\n",
    "locations['Zoo'] = (52.507216, 13.332271)\n",
    "locations['FreieUni'] = (52.452526, 13.289679)\n",
    "locations['Potsdamer'] = (52.508969, 13.376300)\n",
    "locations['Kottbusser'] = (52.499083, 13.418140)\n",
    "locations['Rosenthaler'] = (52.529650, 13.401321)\n",
    "locations['Hauptbahnhof'] = (52.52493, 13.369181)\n",
    "\n",
    "# TODO:\n",
    "# Add the coordinates of an interesting place to the dictionary\n",
    "# TIP:\n",
    "# locations['...'] = (...)\n",
    "\n",
    "# calculate distances to all rows\n",
    "for k, place in locations.items():\n",
    "    distances = lambda x: great_circle((x['latitude'], x['longitude']), place).km\n",
    "\n",
    "    if 'dist_{k}' not in odata:\n",
    "        odata[f'dist_{k}'] = odata.apply(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Outliers\n",
    "\n",
    "- calculate the z-scores\n",
    "- here, outliers have a Z-Score > 3\n",
    "- visualize the data, with and withodata outliers and log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to calculate z-scores\n",
    "\n",
    "class ZScore:\n",
    "    def __init__(self, d):\n",
    "        self.m = np.mean(d)\n",
    "        self.s = np.std(d)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return np.abs((x - self.m) / self.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute z-scores > 3 with the mean\n",
    "\n",
    "# exclude specific variables\n",
    "exclude = []\n",
    "exclude += ['dist']\n",
    "exclude += ['lat']\n",
    "exclude += ['lon']\n",
    "exclude += ['host_id']\n",
    "exclude += ['square_feet']\n",
    "exclude += get_dichotomous(odata)\n",
    "\n",
    "pattern = f'^(?!{\"|\".join(exclude)}).*'\n",
    "variables = odata.select_dtypes(np.number).filter(regex=pattern, axis=1).columns\n",
    "\n",
    "# mean impute z-scores > 3\n",
    "for v in variables:\n",
    "    # TODO:\n",
    "    # Create the outlier mask\n",
    "    # which is true for z-scores > 3.\n",
    "    # Instantiate the \"ZScore\" class\n",
    "    # and apply it like a function.\n",
    "\n",
    "    # TIP:\n",
    "    # mask = odata[v].apply(...) > ...\n",
    "\n",
    "    mask = odata[v].apply(ZScore(odata[v])) > 3 # REMOVE\n",
    "\n",
    "    contains_outliers = mask.sum() > 0\n",
    "    if contains_outliers:\n",
    "        odata[f'imp_z_{v}'] = mask.astype(int)\n",
    "        odata.loc[mask, v] = odata[v].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if len(odata.filter(regex='^imp_z.*').columns) == 14:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of variables found, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for neighbourhood price\n",
    "\n",
    "figsize = (12, 15)\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=figsize, sharex=True)\n",
    "\n",
    "vs = ['neighbourhood_group_cleansed', 'price']\n",
    "tmp = odata[vs]\n",
    "\n",
    "# boxplot\n",
    "sns.boxplot(x=vs[0], y=vs[1], data=odata, showfliers=False, ax=axs[0])\n",
    "\n",
    "# TODO:\n",
    "# Create a violin plot of the \"price\" for each \"neighbourhood_group_cleansed\".\n",
    "# Use the example below as a template.\n",
    "# Compare the results with and without log transformation.\n",
    "\n",
    "# TIP:\n",
    "# sns.violinplot(...)\n",
    "\n",
    "sns.violinplot(data=odata, x=vs[0], y=vs[1], ax=axs[1]) # REMOVE\n",
    "\n",
    "\n",
    "# violin plot with log price\n",
    "\n",
    "tmp['log_price'] = np.log(tmp['price']+1)\n",
    "sns.violinplot(data=tmp, x=vs[0], y='log_price', ax=axs[2])\n",
    "\n",
    "axs[-1].tick_params(axis='x', rotation=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing Values\n",
    "\n",
    "- with imputation indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with \"0\"\n",
    "\n",
    "vs = [\"cleaning_fee\", \"security_deposit\", 'host_is_superhost', 'years_registered']\n",
    "nvs = [f'imp_{v}' for v in vs]\n",
    "\n",
    "if nvs[0] not in odata:\n",
    "    # TODO:\n",
    "    # Create the variables from the \"nvs\" list,\n",
    "    # which hold the 0/1 indicator if a variable is imputed.\n",
    "    # Imputed -> True -> 1\n",
    "    # Use the pandas functions \"isnull\" and \"astype\".\n",
    "\n",
    "    # TIP:\n",
    "    # odata[nvs] = odata[vs]...\n",
    "\n",
    "    odata[nvs] = odata[vs].isnull().astype(int) # REMOVE\n",
    "\n",
    "    # TODO:\n",
    "    # Fill null values with 0\n",
    "    # for the variables in \"vs\"\n",
    "    # Use pandas \"fillna\" function.\n",
    "    \n",
    "    # TIP:\n",
    "    # result = ...\n",
    "    \n",
    "    result = odata[vs].fillna(0) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if odata['imp_security_deposit'].sum() == 9361:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of imputations found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if (result['cleaning_fee'] == 0).sum() == 9011:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of zeros found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata[vs] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with the mean\n",
    "\n",
    "vs = []\n",
    "vs += ['review_scores_rating']\n",
    "vs += ['review_scores_cleanliness']\n",
    "vs += ['review_scores_location']\n",
    "vs += ['bathrooms']\n",
    "vs += ['bedrooms']\n",
    "vs += ['beds']\n",
    "vs += ['square_meter']\n",
    "\n",
    "nvs = [f'imp_{v}' for v in vs]\n",
    "\n",
    "if nvs[0] not in odata:\n",
    "    odata[nvs] = odata[vs].isnull().astype(int)\n",
    "\n",
    "    # TODO:\n",
    "    # Impute the values with their respective mean value\n",
    "    # Use pandas \"fillna\" function\n",
    "\n",
    "    # TIP:\n",
    "    # result = odata[vs]...\n",
    "    \n",
    "    result = odata[vs].fillna(odata[vs].mean()) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if odata['imp_review_scores_cleanliness'].sum() == 4411:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of imputations found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if result['review_scores_cleanliness'].isna().sum() == 0:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** still na values found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if False not in passed:\n",
    "    odata[vs] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with the mode\n",
    "\n",
    "vs = []\n",
    "vs += ['host_since']\n",
    "vs += ['host_since_cat']\n",
    "\n",
    "nvs = [f'imp_{v}' for v in vs]\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for v, nv in zip(vs, nvs):\n",
    "    if nv not in odata:\n",
    "        odata[nv] = odata[v].isnull().astype(int)\n",
    "\n",
    "    if v in odata:\n",
    "\n",
    "        # TODO:\n",
    "        # Impute the values with their respective mode value\n",
    "        # Use pandas \"fillna\" function\n",
    "        # Be careful with the return type of mode, may need some indexing\n",
    "\n",
    "        # TIP:\n",
    "        # result[v] = odata[v]...\n",
    "        \n",
    "        result[v] = odata[v].fillna(odata[v].mode()[0]) # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if odata['imp_host_since'].sum() == 26:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of imputations found, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if 'host_since' in odata:\n",
    "    if result['host_since'].isna().sum() == 0:\n",
    "        print('*** passed, well done!')\n",
    "    else:\n",
    "        print('*** still na values found, try again')\n",
    "        passed.append(False)\n",
    "\n",
    "    if False not in passed:\n",
    "        odata[vs] = result[vs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = []\n",
    "vs += ['description']\n",
    "vs += ['space']\n",
    "vs += ['square_feet']\n",
    "vs += ['amenities']\n",
    "vs += ['host_since']\n",
    "\n",
    "# TODO:\n",
    "# Why would including\n",
    "# \"imp_z_price\" be data leakage?\n",
    "\n",
    "vs += ['imp_z_price']\n",
    "\n",
    "odata = odata.drop(vs, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nullity\n",
    "\n",
    "tmp = odata.isnull().sum() / len(data) * 100\n",
    "for k, v in tmp.items():\n",
    "    if v > 0:\n",
    "        print(f'{k} {v:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for variables without variance\n",
    "\n",
    "for k, v in odata.items():\n",
    "    u = pd.unique(v)\n",
    "    if len(v) < 2:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data to Disk\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well done! Now the results.\n",
    "\n",
    "odata.to_csv(ofname, header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Data Report\n",
    "\n",
    "To check your features\\\n",
    "please generate the feature report\\\n",
    "by running the notebook:\n",
    "\n",
    "`create_repots.ipynb`\n",
    "\n",
    "This will generated the report of the feature data:\n",
    "\n",
    "./plots/data_report_features.html\n",
    "\n",
    "It is an html file so view it in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# there could be more features to be discovered and extracted.\n",
    "# Have a look at the categorical variables.\n",
    "\n",
    "variables = ['description', 'space']\n",
    "data[variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('3o10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "24bd5b2c4284f955ab7628ddca6a5f285d231065025c4cec3682ee9df201cb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
