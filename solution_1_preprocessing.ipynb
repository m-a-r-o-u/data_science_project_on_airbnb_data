{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Preparation\n",
    "\n",
    "---\n",
    "\n",
    "Content\n",
    "\n",
    "- Data Exploration\n",
    "\n",
    "- Data Preprocessing\n",
    "\n",
    "- Feature Engineering\n",
    "\n",
    "- Save Features to Disk\n",
    "\n",
    "\n",
    "\n",
    "Additional Material:\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Central Concepts\n",
    "\n",
    "- Data Leakage\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib color settings\n",
    "\n",
    "dark_plot_theme = True\n",
    "\n",
    "if dark_plot_theme:\n",
    "    plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load general dependencies\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# for geographic data\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from geopy.distance import great_circle \n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload ./utils.py\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import get_dichotomous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas display settings\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the working directory\n",
    "\n",
    "cwd = Path()\n",
    "\n",
    "opath = cwd / 'data'\n",
    "ppath = cwd / 'plots'\n",
    "\n",
    "opath.mkdir(exist_ok=True)\n",
    "ppath.mkdir(exist_ok=True)\n",
    "\n",
    "ifname = opath / 'listings.csv'\n",
    "ofname = opath / 'features.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset\n",
    "\n",
    "- extract important columns of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw dataset\n",
    "\n",
    "index = ['id']\n",
    "\n",
    "cnames = []\n",
    "cnames += [\"space\"]\n",
    "cnames += [\"description\"]\n",
    "cnames += [\"host_since\"]\n",
    "cnames += [\"host_is_superhost\"]\n",
    "cnames += [\"neighbourhood_group_cleansed\"]\n",
    "cnames += [\"latitude\"]\n",
    "cnames += [\"longitude\"]\n",
    "cnames += [\"room_type\"]\n",
    "cnames += [\"bathrooms\"]\n",
    "cnames += [\"bedrooms\"]\n",
    "cnames += [\"beds\"]\n",
    "cnames += [\"amenities\"]\n",
    "cnames += [\"square_feet\"]\n",
    "cnames += [\"price\"]\n",
    "cnames += [\"cleaning_fee\"]\n",
    "cnames += [\"security_deposit\"]\n",
    "cnames += [\"minimum_nights\"]\n",
    "cnames += [\"number_of_reviews\"]\n",
    "cnames += [\"review_scores_rating\"]\n",
    "cnames += [\"review_scores_cleanliness\"]\n",
    "cnames += [\"review_scores_location\"]\n",
    "cnames += [\"instant_bookable\"]\n",
    "cnames += [\"host_id\"]\n",
    "cnames += index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# load in the csv file: ifname\n",
    "# use pandas pd.read_csv\n",
    "# and specify columns: cnames\n",
    "# and the index column: index\n",
    "\n",
    "# data = ...\n",
    "data = pd.read_csv(ifname, usecols=cnames, index_col=index).sort_index(axis=1) # REMOVE\n",
    "\n",
    "# process and gather features in odata\n",
    "odata = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if len(data.columns) == 23:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong number of columns, try again')\n",
    "\n",
    "if data.index.name == 'id':\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** wrong index, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "The raw data exploration is done with\\\n",
    "the help of the pandas-profiling package.\n",
    "\n",
    "The report is generated by running the notebook:\n",
    "\n",
    "create_repots.ipynb\n",
    "\n",
    "This will generated the reportin the plots subfolder:\n",
    "\n",
    "./plots/data_report_raw.html.\n",
    "\n",
    "View it in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove duplicate rows\n",
    "\n",
    "- process text\n",
    "\n",
    "- change variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform monetary string to numeric variables\n",
    "\n",
    "variables = ['price', 'cleaning_fee', 'security_deposit']\n",
    "\n",
    "for v in variables:\n",
    "    if odata[v].dtype != 'float':\n",
    "\n",
    "        # TODO:\n",
    "        # The variables in \"variables\" in the DataFrame \"odata\"\n",
    "        # are strings convert them into floats.\n",
    "        # and overwrite them in \"odata\".\n",
    "        # For that remove the characters: \"$\" and \",\"\n",
    "        # with pandas \".replace\" from the pandas \"str\" functions\n",
    "        # and then use astype()\n",
    "\n",
    "        # odata[v] = ...\n",
    "        odata[v] = odata[v].str.replace('[$,]', '', regex=True).astype(float) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if all(np.array(odata[variables].dtypes) == 'float'):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables are not float, try again')\n",
    "\n",
    "\n",
    "if odata['price'].sum() == 1514224.0:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata['host_is_superhost'].isnull().sum() == 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform boolean strings to numbers\n",
    "\n",
    "variables = ['host_is_superhost', 'instant_bookable']\n",
    "\n",
    "d = {'t': 1., 'f': 0.}\n",
    "\n",
    "for v in variables:\n",
    "    if odata[v].dtype == 'O':\n",
    "\n",
    "        # TODO:\n",
    "        # Convert the variables from string to float\n",
    "        # and overwrite them in \"odata\".\n",
    "        # For that use the provided dictionary d\n",
    "        # and the pandas \".map\" function.\n",
    "        # Also specify how to handle Null values in the mapping.\n",
    "\n",
    "        # odata[v] = ...\n",
    "\n",
    "        odata[v] = odata[v].map(d, na_action='ignore') # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if odata['host_is_superhost'].sum() == 3011:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')\n",
    "\n",
    "\n",
    "if odata['host_is_superhost'].isnull().sum() == 26:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** variables do not add up, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specific amenities from the \n",
    "\n",
    "amenities = odata['amenities'].str.strip('{}').str.replace('\"', '').str.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Count the occurance of the individual amenities in the variables \"amenities\"\n",
    "# First flatten the nested \"amenities\" variable with panda \"explode\" function.\n",
    "# Then use the \"Counter\" class from the \"collections\" library.\n",
    "# Counter: dict like, stores names as keys and counts as values\n",
    "\n",
    "# counter = ...\n",
    "\n",
    "counter = Counter(amenities.explode()) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if counter['TV'] == 10134:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the TV in counter does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot found amenities\n",
    "\n",
    "# the 74 most frequent amenities\n",
    "df_counter = pd.DataFrame(list(counter.items()), columns=['amenities', 'count']).sort_values('count', ascending=False).head(75)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 12))\n",
    "\n",
    "# TODO:\n",
    "# Visualize the amenities in the df_counter DataFrame.\n",
    "# Use the \"barplot\" function from the \"seaborn\" (imported as sns) library\n",
    "# Set the x to \"count\" and y to \"amenities\".\n",
    "# What is the most frequent amenitiy?\n",
    "\n",
    "# sns.barplot(...)\n",
    "sns.barplot(data=df_counter, y='amenities', x='count'); # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dummy variables for the amenities\n",
    "\n",
    "features = []\n",
    "\n",
    "nv = 'family'\n",
    "pattern = 'Crib|Family/kid friendly|Baby|Children'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'smoking'\n",
    "pattern = 'Smoking allowed'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'TV'\n",
    "pattern = 'TV'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'internet'\n",
    "pattern = 'WiFi|Internet'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'pets'\n",
    "pattern = 'Pets allowed'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "nv = 'parking'\n",
    "pattern = 'Parking|parking'\n",
    "features += [(nv, pattern)]\n",
    "\n",
    "v = 'amenities'\n",
    "for nv, pattern in features:\n",
    "    # TODO:\n",
    "    # We create new dummy variables if special amenities are present\n",
    "    # The new variable names \"nv\" are looped over together with the \"pattern\".\n",
    "    # If the pattern is present return true and cast this as 1.\n",
    "    # For this use \"contains\" from the pandas string functions\n",
    "    # and set the type with astype to integer \n",
    "\n",
    "    # odata[nv] = odata[v].str...\n",
    "    odata[nv] = odata[v].str.contains(pattern).astype('uint8') # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if odata['internet'].sum() == 7909:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the internet variable does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up kitchen amenities\n",
    "\n",
    "nv = 'basic_kitchen'\n",
    "dtype = 'uint8'\n",
    "odata[nv] = np.sum([odata[v].str.contains('Coffee').astype(dtype),\n",
    "                  odata[v].str.contains('Dishes').astype(dtype),\n",
    "                  odata[v].str.contains('Oven').astype(dtype),\n",
    "                  odata[v].str.contains('Dishwasher').astype(dtype),\n",
    "                  odata[v].str.contains('Microwave').astype(dtype),\n",
    "                  odata[v].str.contains('Refrigerator').astype(dtype),\n",
    "                  odata[v].str.contains('Dishwasher').astype(dtype),\n",
    "                  odata[v].str.contains('Cooking basics').astype(dtype)],\n",
    "                 axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract square meters from the description\n",
    "\n",
    "v = 'square_feet'\n",
    "nv = 'square_meter'\n",
    "\n",
    "pattern = '(\\d{2,4})\\s?(sq\\s*m|square\\s*m|quadrate\\s*meter|m2|m\\^2|mÂ²|mq)'\n",
    "m_per_ft = 0.3048\n",
    "\n",
    "sqm_from_desc = data['description'].str.extract(pattern, flags=re.IGNORECASE)[0].astype('float64')\n",
    "\n",
    "# TODO:\n",
    "# Combine the data from the datafrome column \"square_feet\"\n",
    "# with the values extracted into \"sqm_from_desc\"\n",
    "# First change units from SQUARE feet to SQUARE meter using m_per_ft**2\n",
    "# Then use the pandas function \"combine_first\"\n",
    "# To combine the output in to the new variable \"square_meter\" (nv)\n",
    "\n",
    "# odata[nv] = (data[v] ... ).combine_first( ... ) \n",
    "odata[nv] = (data[v] * m_per_ft**2).combine_first(sqm_from_desc) # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if np.floor(odata['square_meter'].sum()) == 285489:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the square_meter variable does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Replace all zeros with np.nan\n",
    "# in the \"square_meter\" variable.\n",
    "# Use the pandas \"replace\" function\n",
    "\n",
    "# odata[nv] = odata[nv]...\n",
    "odata[nv] = odata[nv].replace(0, np.nan) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if (odata[nv] < 0.1).sum() == 0:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the numbers do not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of listings per host\n",
    "# using a pandas cookbook trick\n",
    "\n",
    "# TODO:\n",
    "# Create the new variable 'listings/host' in odata\n",
    "# which contains the count of listings per host\n",
    "# This trick works by grouping the data after the \"host_id\"\n",
    "# and then using \"transform\" to count the elements in each group\n",
    "# with the \"len\" function\n",
    "# But you need a second dummy variable: \"beds\"\n",
    "\n",
    "# odata['listings/host'] = odata[['host_id', ...]].groupby(...).transform(...); \n",
    "odata['listings/host'] = odata[['host_id', 'beds']].groupby(\"host_id\").transform(len); # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if odata['listings/host'][2015] == 4:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the variable does not add up, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of years_registered\n",
    "\n",
    "class YSR:\n",
    "    def __init__(self, dates):\n",
    "        self.reference = dates.max()\n",
    "\n",
    "    def __call__(self, date):\n",
    "        return np.abs((self.reference - date).days / 356)\n",
    "\n",
    "# TODO:\n",
    "# To calculate the \"years_registered\" feature\n",
    "# The feature \"host_since\" needs to be converted to_datetime.\n",
    "# Use the pandas utility function to_datetime\n",
    "\n",
    "v = 'host_since'\n",
    "# host_since = pd...\n",
    "host_since = pd.to_datetime(odata[v]) # REMOVE\n",
    "\n",
    "odata['years_registered'] = host_since.apply(YSR(host_since))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if isinstance(host_since.iloc[0], datetime.datetime):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** the variable does not add up, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning of years_registered\n",
    "\n",
    "bins = [0, 1, 4, np.inf]\n",
    "\n",
    "groups = ['Newbies','Experienced','Professionals']\n",
    "\n",
    "# TODO:\n",
    "# ...\n",
    "\n",
    "# odata['host_since_cat'] = pd...\n",
    "odata['host_since_cat'] = pd.cut(odata['years_registered'], bins, labels=groups) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show years_registered\n",
    "\n",
    "sns.countplot(x=odata['host_since_cat']);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encode\n",
    "\n",
    "vs = ['room_type', 'neighbourhood_group_cleansed', 'host_since_cat']\n",
    "\n",
    "\n",
    "dummies = pd.get_dummies(odata[vs])\n",
    "odata = odata.join(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot a map of berlin\n",
    "- use the price for color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download/extract berlin shape files\n",
    "\n",
    "url = \"https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.shp.zip\"\n",
    "\n",
    "shp_folder = opath / 'berlin_shape_files'\n",
    "shp_folder.mkdir(exist_ok=True)\n",
    "shp_fname_zip = shp_folder / os.path.basename(url)\n",
    "\n",
    "response = requests.get(url)\n",
    "open(shp_fname_zip, \"wb\").write(response.content);\n",
    "\n",
    "with zipfile.ZipFile(shp_fname_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(shp_folder)\n",
    "\n",
    "shp_fname = list(opath.rglob('*.shp'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spatial price distribution\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "figsize = (12, 8)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "\n",
    "berlin = gpd.read_file(shp_fname)\n",
    "berlin.plot(edgecolor='black', ax=ax);\n",
    "\n",
    "scatter_plot = ax.scatter(odata['longitude'], odata['latitude'], c=odata['price'], cmap='inferno_r', vmax=600, s=0.7)\n",
    "cbar = plt.colorbar(scatter_plot, ax=ax)\n",
    "cbar.ax.set_ylabel('price')\n",
    "\n",
    "ax.set_title('Berlin', fontsize='xx-large')\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=0)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add variables that contain the distance to important places like the central station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances to special places\n",
    "\n",
    "\n",
    "# the lat/lon coordinates of special places\n",
    "locations = {}\n",
    "locations['Zoo'] = (52.507216, 13.332271)\n",
    "locations['FreieUni'] = (52.452526, 13.289679)\n",
    "locations['Potsdamer'] = (52.508969, 13.376300)\n",
    "locations['Kottbusser'] = (52.499083, 13.418140)\n",
    "locations['Rosenthaler'] = (52.529650, 13.401321)\n",
    "locations['Hauptbahnhof'] = (52.52493, 13.369181)\n",
    "\n",
    "\n",
    "# calculate distances to all rows\n",
    "for k, place in locations.items():\n",
    "    distances = lambda x: great_circle((x['latitude'], x['longitude']), place).km\n",
    "    odata[f'dist_{k}'] = odata.apply(distances, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Outliers\n",
    "\n",
    "- calculate the z-scores\n",
    "- here, outliers have a Z-Score > 3\n",
    "- visualize the data, with and withodata outliers and log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to calculate z-scores\n",
    "\n",
    "class ZScore:\n",
    "    def __init__(self, d):\n",
    "        self.m = np.mean(d)\n",
    "        self.s = np.std(d)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return np.abs((x - self.m) / self.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute z-scores > 3 with the mean\n",
    "\n",
    "# exclude specific variables\n",
    "exclude = []\n",
    "exclude += ['dist']\n",
    "exclude += ['lat']\n",
    "exclude += ['lon']\n",
    "exclude += ['host_id']\n",
    "exclude += ['square_feet']\n",
    "exclude += get_dichotomous(odata)\n",
    "\n",
    "pattern = f'^(?!{\"|\".join(exclude)}).*'\n",
    "variables = odata.select_dtypes(np.number).filter(regex=pattern, axis=1).columns\n",
    "\n",
    "# mean impute z-scores > 3\n",
    "for v in variables:\n",
    "    mask = odata[v].apply(ZScore(odata[v])) > 3\n",
    "    are_outliers = mask.sum() > 0\n",
    "\n",
    "    if are_outliers:\n",
    "        odata[f'imp_z_{v}'] = mask.astype(int)\n",
    "\n",
    "        # mean impute\n",
    "        odata.loc[mask, v] = odata[v].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for neighbourhood price\n",
    "\n",
    "figsize = (12, 15)\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=figsize, sharex=True)\n",
    "\n",
    "vs = ['neighbourhood_group_cleansed', 'price']\n",
    "\n",
    "# boxplot\n",
    "g = sns.boxplot(x=vs[0], y=vs[1], data=odata, showfliers=False, ax=axs[0])\n",
    "\n",
    "# violin plot\n",
    "tmp = odata[vs]\n",
    "g = sns.violinplot(data=tmp, x=vs[0], y=vs[1], ax=axs[1])\n",
    "\n",
    "# violin plot with log price\n",
    "tmp['log_price'] = np.log(tmp['price']+1)\n",
    "g = sns.violinplot(data=tmp, x=vs[0], y='log_price', ax=axs[2])\n",
    "\n",
    "axs[-1].tick_params(axis='x', rotation=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with imputation indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with \"0\"\n",
    "\n",
    "variables = [\"cleaning_fee\", \"security_deposit\", 'host_is_superhost', 'years_registered']\n",
    "new_variables = [f'imp_{v}' for v in variables]\n",
    "\n",
    "odata[new_variables] = odata[variables].isnull().astype(int)\n",
    "odata[variables] = odata[variables].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with the mean\n",
    "\n",
    "vs = []\n",
    "vs += ['review_scores_rating']\n",
    "vs += ['review_scores_cleanliness']\n",
    "vs += ['review_scores_location']\n",
    "vs += ['bathrooms']\n",
    "vs += ['bedrooms']\n",
    "vs += ['beds']\n",
    "vs += ['square_meter']\n",
    "\n",
    "nvs = [f'imp_{v}' for v in vs]\n",
    "\n",
    "odata[nvs] = odata[vs].isnull().astype(int)\n",
    "odata[vs] = odata[vs].fillna(odata[vs].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with the mode\n",
    "\n",
    "vs = []\n",
    "vs += ['host_since']\n",
    "vs += ['host_since_cat']\n",
    "\n",
    "nvs = [f'imp_{v}' for v in vs]\n",
    "\n",
    "for v, nv in zip(vs, nvs):\n",
    "    odata[nv] = odata[v].isnull().astype(int)\n",
    "    odata[v] = odata[v].fillna(odata[v].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = []\n",
    "vs += ['description']\n",
    "vs += ['space']\n",
    "vs += ['square_feet']\n",
    "vs += ['imp_z_price']\n",
    "vs += ['amenities']\n",
    "\n",
    "vs += ['host_since']\n",
    "\n",
    "try:\n",
    "    odata = odata.drop(vs, axis=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nullity\n",
    "\n",
    "tmp = odata.isnull().sum() / len(data) * 100\n",
    "for k, v in tmp.items():\n",
    "    if v > 0:\n",
    "        print(f'{k} {v:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for variables without variance\n",
    "\n",
    "for k, v in odata.items():\n",
    "    u = pd.unique(v)\n",
    "    if len(v) < 2:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata.to_csv(ofname, header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('3o10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "24bd5b2c4284f955ab7628ddca6a5f285d231065025c4cec3682ee9df201cb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
