{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Classification\n",
    "---\n",
    "\n",
    "**Content**\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "- Decision Trees\n",
    "\n",
    "- Ensemble Methods\n",
    "\n",
    "**Additional Material**\n",
    "\n",
    "- very cool visualization from [r2d3](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_plot_theme = True\n",
    "\n",
    "if dark_plot_theme:\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "\n",
    "# pandas display settings\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and refresh custom functions\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import get_dichotomous\n",
    "from utils import roc_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save experiment metrics \n",
    "\n",
    "exps = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assume: no nulls, no outliers (z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the directory and load the data\n",
    "\n",
    "cwd = Path()\n",
    "\n",
    "ipath = cwd / 'data'\n",
    "\n",
    "ipath.mkdir(exist_ok=True)\n",
    "\n",
    "ifile = ipath / 'features.csv'\n",
    "data = pd.read_csv(ifile, index_col=['id'])\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove imputations from the target variable\n",
    "\n",
    "var = 'review_scores_rating'\n",
    "\n",
    "mask = ((data[f'imp_z_{var}'] + data[f'imp_{var}']) == 0)\n",
    "\n",
    "cdata = data[mask].dropna()\n",
    "\n",
    "target = 'top_rating'\n",
    "\n",
    "if target not in cdata:\n",
    "    rel = (cdata[var] == 100).sum() / len(cdata[var]) * 100\n",
    "\n",
    "    # TODO:\n",
    "    # Define the new target\n",
    "    # Select only the highest ratings\n",
    "    # And save as type \"int\"\n",
    "\n",
    "    # TIP:\n",
    "    # cdata[target] = ...\n",
    "\n",
    "    cdata[target] = (cdata[var] == 100).astype('uint8') # REMOVE\n",
    "    \n",
    "    cdata = cdata.drop(var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if cdata[target].sum() == 6043:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot basis of the new target\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(data=data, x=var, ax=axs[0]);\n",
    "sns.histplot(data=data[mask], x=var, ax=axs[1]);\n",
    "\n",
    "print(f'Top Ratings: {rel:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$logreg = \\frac{1}{1-exp(-z)}$\n",
    "\n",
    "$z = \\beta_0 + x_{i1}\\beta_1 + ...$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "\n",
    "# select numeric only\n",
    "ldata = cdata.select_dtypes(include=np.number)\n",
    "\n",
    "# drop dichotomous features (keep it simple)\n",
    "cols = [x for x in get_dichotomous(ldata) if x != target]\n",
    "ldata = ldata.drop(cols, axis=1)\n",
    "\n",
    "ldata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# Instantiate \"LogisticRegression\"\n",
    "# with the \"linlinear\" solver.\n",
    "# And fit the model\n",
    "# to the training data using \".fit\"\n",
    "\n",
    "# TIP:\n",
    "# logreg = ...\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0) # REMOVE\n",
    "logreg.fit(xtrain, ytrain); # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if isinstance(logreg, LogisticRegression):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "try:\n",
    "    check_is_fitted(logreg)\n",
    "    print('*** passed, well done!')\n",
    "except:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Use \"logreg\" to make predictions\n",
    "# and get the decision probablilites\n",
    "\n",
    "# TIP:\n",
    "# ypred = \n",
    "# yprob = \n",
    "\n",
    "ypred = logreg.predict(xtest) # REMOVE\n",
    "yprob = logreg.predict_proba(xtest) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if isinstance(ypred, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if isinstance(yprob, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Visualize the results.\n",
    "# Apply the provided \"roc_wrapper\" convenience function\n",
    "# with the signature: \"roc_wrapper(ytest, ypred, yprob)\"\n",
    "# and save the results in the exps dict.\n",
    "\n",
    "# TIP:\n",
    "# exps['logreg_1] = ...\n",
    "\n",
    "exps['logreg_1'] = roc_wrapper(ytest, ypred, yprob) # REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improve that!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "\n",
    "cor = np.abs(ldata.drop(get_dichotomous(ldata), axis=1).corr())\n",
    "\n",
    "# absolute correlation\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.heatmap(cor, annot=False, cmap=plt.cm.Blues, vmin=0, vmax=1, ax=axs[0]);\n",
    "\n",
    "# absolution correlation > 0.7\n",
    "sns.heatmap(cor.where(cor>0.7, other=0), annot=False, cmap=plt.cm.Blues, vmin=0, vmax=1, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the correlated feature\n",
    "\n",
    "if 'host_id' in ldata:\n",
    "    # TODO\n",
    "    # \"host_id\" and \"years_registered\" are correlated\n",
    "    # Remove \"host_id\" from \"ldata\"\n",
    "\n",
    "    # TIP:\n",
    "    # result = ldata...\n",
    "\n",
    "    result = ldata.drop('host_id', axis=1) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if 'host_id' not in result:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    ldata = result\n",
    "    print('*** something went wrong, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "# apply logistic regression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(xtrain, ytrain);\n",
    "\n",
    "# make predictions\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "yprob = logreg.predict_proba(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['logreg_2'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix for the default threshold\n",
    "\n",
    "# TODO\n",
    "# Use the sklearn function \"confusion_matrix\"\n",
    "# to extract the: TrueNegatives, FalsePositives, FalseNegatives and TruePositives\n",
    "# Use the \"np.ravel\" function on the output of \"confusion_matrix\"\n",
    "\n",
    "# TIP:\n",
    "# tn, fp, fn, tp = \n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, ypred, normalize='all').ravel() # REMOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if tn < 1:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap([[tp, fp],[fn, tn]], cmap='Blues', vmax=1, annot=True, xticklabels=[1, 0], yticklabels=[1, 0], ax=ax);\n",
    "\n",
    "ax.xaxis.tick_top();\n",
    "ax.xaxis.set_label_position('top');\n",
    "ax.set_xlabel('Actual');\n",
    "ax.set_ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Imputation Flags\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to include imputation flags only\n",
    "\n",
    "pattern = '^imp.*'\n",
    "\n",
    "# TODO\n",
    "# Filter \"cdata\" for the regex in \"pattern\"\n",
    "# save the result in \"tmp\"\n",
    "\n",
    "# TIP:\n",
    "# tmp = cdata...\n",
    "\n",
    "tmp = cdata.filter(regex=pattern) # REMOVE\n",
    "\n",
    "# add target back in\n",
    "tmp = tmp.join(cdata[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if np.shape(tmp) == (17874, 27):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = tmp.drop(target, axis=1)\n",
    "y = tmp[target]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "\n",
    "# apply logistic regression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(xtrain, ytrain);\n",
    "\n",
    "\n",
    "# make predictions\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "yprob = logreg.predict_proba(xtest)\n",
    "\n",
    "# plot roc\n",
    "\n",
    "exps['logreg_3'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xtrain, ytrain)\n",
    "\n",
    "ypred = dt.predict(xtest)\n",
    "yprob = dt.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['dt_1'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Extract the number of tree leaves\n",
    "# and the tree depth from \"dt\"\n",
    "\n",
    "# TIP:\n",
    "# leaves = dt...\n",
    "# depth = dt...\n",
    "\n",
    "leaves = dt.get_n_leaves() # REMOVE\n",
    "depth = dt.get_depth() # REMOVE\n",
    "\n",
    "print(\"number of leaves:\", leaves)\n",
    "print(\"depth of the tree:\", depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "if leaves < 1700:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "\n",
    "\n",
    "if depth < 35:\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "\n",
    "# TODO:\n",
    "# Instantiate and fit a \"DecisionTreeClassifier\"\n",
    "# Set \"max_depth\" to 5 and \"min_samples_leaf\" to 100\n",
    "\n",
    "# TIP:\n",
    "# dt = ...\n",
    "# dt...\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5, min_samples_leaf=100) # REMOVE\n",
    "dt.fit(xtrain, ytrain) # REMOVE\n",
    "\n",
    "ypred = dt.predict(xtest)\n",
    "yprob = dt.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if isinstance(dt, DecisionTreeClassifier):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "try:\n",
    "    check_is_fitted(dt)\n",
    "    print('*** passed, well done!')\n",
    "except:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if isinstance(ypred, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if isinstance(yprob, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of leaves:\", dt.get_n_leaves())\n",
    "print(\"depth of the tree:\", dt.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['dt_2'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12, 10)\n",
    "plt.figure(figsize=figsize)\n",
    "plot_tree(dt, max_depth=2, filled=True, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "**Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Fit and predict \"RandomForestClassifier\"\n",
    "# Set \"n_estimators\" in \"RandomForestClassifier\"\n",
    "# to the \"n_estimators\" variable. \n",
    "\n",
    "# TIP\n",
    "#rf = ...\n",
    "#rf...\n",
    "\n",
    "#ypred = ...\n",
    "#yprob = ...\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators) # REMOVE\n",
    "rf.fit(xtrain, ytrain) # REMOVE\n",
    "\n",
    "ypred = rf.predict(xtest) # REMOVE\n",
    "yprob = rf.predict_proba(xtest) # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "passed = []\n",
    "\n",
    "if isinstance(rf, RandomForestClassifier):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "try:\n",
    "    check_is_fitted(rf)\n",
    "    print('*** passed, well done!')\n",
    "except:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if isinstance(ypred, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)\n",
    "\n",
    "if isinstance(yprob, np.ndarray):\n",
    "    print('*** passed, well done!')\n",
    "else:\n",
    "    print('*** something went wrong, try again')\n",
    "    passed.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['rf'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ada Boost**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "ab = AdaBoostClassifier(n_estimators=n_estimators)\n",
    "ab.fit(xtrain, ytrain)\n",
    "\n",
    "# predict\n",
    "ypred = ab.predict(xtest)\n",
    "yprob = ab.predict_proba(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['ab'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosted Trees**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "gb = GradientBoostingClassifier(n_estimators=n_estimators)\n",
    "gb.fit(xtrain, ytrain)\n",
    "\n",
    "# predict\n",
    "ypred = gb.predict(xtest)\n",
    "yprob = gb.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "exps['gb'] = roc_wrapper(ytest, ypred, yprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_summary = pd.DataFrame(exps)\n",
    "metric_summary.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Summary**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini feature importance\n",
    "\n",
    "models = {}\n",
    "models['dt'] = dt\n",
    "models['rf'] = rf\n",
    "models['ab'] = ab\n",
    "models['gb'] = gb\n",
    "\n",
    "imp_summary = pd.DataFrame()\n",
    "\n",
    "for k, v in models.items():\n",
    "\n",
    "    # TODO:\n",
    "    # Extract \"feature_names_in_\"\n",
    "    # and \"feature_importances_\"\n",
    "    # from the model in variable \"v\"\n",
    "\n",
    "    # TIP\n",
    "    # names = v...\n",
    "    # imp = v...\n",
    "    \n",
    "    names = v.feature_names_in_ # REMOVE\n",
    "    imp = v.feature_importances_ # REMOVE\n",
    "\n",
    "    feature_imp = pd.DataFrame(dict(zip(names, imp[:, None])), index=[k])\n",
    "    imp_summary = pd.concat([imp_summary, feature_imp])\n",
    "\n",
    "imp_summary.T.sort_values('gb', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('3o10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "24bd5b2c4284f955ab7628ddca6a5f285d231065025c4cec3682ee9df201cb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
