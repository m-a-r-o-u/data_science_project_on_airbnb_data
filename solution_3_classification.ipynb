{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Content\n",
    "\n",
    "- Logistic Regression\n",
    "\n",
    "    - ...\n",
    "\n",
    "- Single Decision Trees\n",
    "\n",
    "    - ...\n",
    "\n",
    "- Tree Ensemble Methods\n",
    "\n",
    "ToDo:\n",
    "\n",
    "- LogReg: ROC curve only from the missing values\n",
    "\n",
    "- LogReg: The problem with correlated values\n",
    "\n",
    "Additional Material:\n",
    "\n",
    "- very cool visualization from [r2d3](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Concepts\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "$logreg = \\frac{1}{1-exp(-z)}$\n",
    "\n",
    "$z = \\beta_0 + x_{i1}\\beta_1 + ...$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Content from the slides\n",
    "\n",
    "Decision Tree\n",
    "- Classification or Regression: Explain how!\n",
    "- CART algorithm\n",
    "- Purity of a sample? Gini-Index, Entropy, Chi-square, Information Gain\n",
    "- Pruning\n",
    "\n",
    "Ensemble Models\n",
    "- Random Forests\n",
    "- AdaBoost\n",
    "- GradientBoostedTrees\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_plot_theme = True\n",
    "\n",
    "if dark_plot_theme:\n",
    "    plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "# pandas display settings\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clustering metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload ./utils.py\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import get_dichotomous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Feature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assume: no nulls, no outliers (z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the directory and load the data\n",
    "\n",
    "cwd = Path()\n",
    "\n",
    "ipath = cwd / 'data'\n",
    "\n",
    "ipath.mkdir(exist_ok=True)\n",
    "\n",
    "ifile = ipath / 'features.csv'\n",
    "data = pd.read_csv(ifile, index_col=['id'])\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove imputations from the new target variable\n",
    "\n",
    "var = 'review_scores_rating'\n",
    "\n",
    "mask = ((data[f'imp_z_{var}'] + data[f'imp_{var}']) == 0)\n",
    "\n",
    "cdata = data[mask].dropna()\n",
    "\n",
    "target = 'top_rating'\n",
    "\n",
    "if var in cdata:\n",
    "    rel = (cdata[var] == 100).sum() / len(cdata[var]) * 100\n",
    "\n",
    "    cdata[target] = (cdata[var] == 100).astype('uint8')\n",
    "    \n",
    "    cdata = cdata.drop(var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot basis of the new target\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(data=data, x=var, ax=axs[0]);\n",
    "sns.histplot(data=data[mask], x=var, ax=axs[1]);\n",
    "\n",
    "print(f'Top Ratings: {rel:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata = cdata.select_dtypes(include=np.number)\n",
    "\n",
    "# drop dichotomous (keep it simple)\n",
    "cols = get_dichotomous(ldata)\n",
    "ldata = ldata.drop(cols, axis=1)\n",
    "\n",
    "if target not in ldata:\n",
    "    ldata = ldata.join(cdata[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "\n",
    "# apply logistic regression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(xtrain, ytrain);\n",
    "\n",
    "\n",
    "# make predictions\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "yprob = logreg.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look\n",
    "\n",
    "ypred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot probabilities\n",
    "\n",
    "def roc_wrapper(ytest, yprob):\n",
    "    # calculate the ROC values\n",
    "    fpr, tpr, thresholds = roc_curve(ytest, yprob[:,1])\n",
    "\n",
    "    # plot ROC curve\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].plot(fpr, tpr, label='tpr')\n",
    "    axs[0].plot([0,1], [0,1])\n",
    "    axs[0].set_aspect('equal')\n",
    "\n",
    "    # probabilities the model predicts a 1\n",
    "    sns.histplot(yprob[:, 1], ax=axs[1], stat='probability');\n",
    "\n",
    "    axs[1].set_xlim(0, 1)\n",
    "    axs[1].set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_wrapper(ytest, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation\n",
    "\n",
    "#cor = np.abs(ldata.drop(get_dichotomous(ldata), axis=1).corr())\n",
    "\n",
    "# absolute correlation\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#sns.heatmap(cor, annot=False, cmap=plt.cm.Blues, vmin=0, vmax=1, ax=axs[0]);\n",
    "\n",
    "# absolution correlation > 0.7\n",
    "#sns.heatmap(cor.where(cor>0.7, other=0), annot=False, cmap=plt.cm.Blues, vmin=0, vmax=1, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the correlated feature\n",
    "\n",
    "ldata = ldata.drop('host_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "\n",
    "# apply logistic regression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(xtrain, ytrain);\n",
    "\n",
    "\n",
    "# make predictions\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "yprob = logreg.predict_proba(xtest)\n",
    "\n",
    "# plot roc\n",
    "\n",
    "roc_wrapper(ytest, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "\n",
    "cmetrics = {}\n",
    "cmetrics['accuracy_score'] = accuracy_score\n",
    "cmetrics['f1_score'] = f1_score\n",
    "cmetrics['precision_score'] = precision_score\n",
    "cmetrics['recall_score'] = recall_score\n",
    "\n",
    "for k, v in cmetrics.items():\n",
    "    metric = v(ytest, ypred)\n",
    "    print(f'{k:16} {metric:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "auc = roc_auc_score(ytest, yprob[:, 1])\n",
    "\n",
    "print(f'AUC: {auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for one threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "# default treshold?\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, ypred, normalize='all').ravel()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap([[tp, fp],[fn, tn]], cmap='Blues', vmax=1, annot=True, xticklabels=[1, 0], yticklabels=[1, 0], ax=ax);\n",
    "\n",
    "ax.xaxis.tick_top();\n",
    "ax.xaxis.set_label_position('top');\n",
    "ax.set_xlabel('Actual');\n",
    "ax.set_ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Imputation Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for imputation flags\n",
    "\n",
    "pattern = '^imp.*'\n",
    "ldata = cdata.filter(regex=pattern)\n",
    "\n",
    "# add target back in\n",
    "ldata = ldata.join(cdata[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "x = ldata.drop(target, axis=1)\n",
    "y = ldata[target]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=0)\n",
    "\n",
    "\n",
    "# apply logistic regression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(xtrain, ytrain);\n",
    "\n",
    "\n",
    "# make predictions\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "yprob = logreg.predict_proba(xtest)\n",
    "\n",
    "# plot roc\n",
    "\n",
    "roc_wrapper(ytest, yprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(ytest, ypred)\n",
    "auc = roc_auc_score(ytest, yprob[:, 1])\n",
    "\n",
    "print(f'AUC: {auc:.2f}')\n",
    "print(f'ACC: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('3o10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "24bd5b2c4284f955ab7628ddca6a5f285d231065025c4cec3682ee9df201cb6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
